import logging
import os
import random
from copy import deepcopy

import numpy as np
import torch
import torch.nn as nn
from matplotlib import pyplot as plt

from attack import frequency_backdoor
from model import models
from clients.Client import Client
from clients.MaliciousClient import MaliciousClient
from utils import utils
from utils.ModelSaver import ModelSaver
from utils.parameters import Params
from defenses.fedavg import FedAvg as Defense
from utils.utils import Inject_trigger, Inject_watermark_test


logger = logging.getLogger('logger')
class Helper:
    params:Params=None
    defence:Defense=None

    def __init__(self,params):
        self.teacher_model = None
        self.params = Params(**params)
        self.client_loss = []
        self.malicious_clients = []
        self.clients = []
        self.global_model = None
        self.dict_users = None
        self.train_dataset = None
        self.test_dataset = None
        self.clients_model = {} # å­˜å‚¨å„å®¢æˆ·ç«¯æœ¬åœ°è®­ç»ƒåçš„æ¨¡å‹å‚æ•°
        self.clients_his_update={} # å­˜å‚¨å„ä¸ªå®¢æˆ·ç«¯æ¨¡å‹çš„å†å²å‚æ•°æ›´æ–°é‡
        self.clients_update={} # å­˜å‚¨å„ä¸ªå®¢æˆ·ç«¯æ¨¡å‹çš„å‚æ•°æ›´æ–°é‡

        self.model_saver = ModelSaver(self.params)# æ¨¡å‹ä¿å­˜
        self.loss_func = None

        self.mask=None # ç”¨äºé€†å‘æ”»å‡»çš„æ©ç 
        self.pattern=None # ç”¨äºé€†å‘æ”»å‡»çš„æ¨¡å¼
        self.delta_z=None # ç”¨äºé€†å‘æ”»å‡»çš„ç‰¹å¾è§¦å‘å™¨

        # æ–°å¢ï¼šç”¨äºç›®æ ‡æ ‡ç­¾æ¨æ–­çš„å¹³æ»‘åˆ†æ•°è®°å½•
        # ç»“æ„: {class_id: smoothed_score}
        self.target_label_inference_scores = {c: 0.0 for c in range(self.params.num_classes)}
        # æ–°å¢ï¼šå¹³æ»‘å› å­
        self.inference_smoothing_alpha = 0.4

        self.setup_seed(20250703)

        self.make_device()
        self.make_dataset()
        self.make_model()
        self.make_clients()
        self.make_loss()
        self.make_defense()
        self.make_attack()

    def make_device(self):
        self.params.device = torch.device(
            'cuda:{}'.format(self.params.gpu) if torch.cuda.is_available() and self.params.gpu != -1 else 'cpu'
        )
    def make_dataset(self):
        # åˆå§‹åŒ–æ•°æ®é›†
        # è®­ç»ƒæ•°æ®é›†  æµ‹è¯•æ•°æ®é›†  æ¯ä¸ªå®¢æˆ·ç«¯å¯¹åº”çš„æ•°æ®æ ·æœ¬
        self.train_dataset, self.test_dataset, self.dict_users = utils.Download_data(self.params.dataset, 'dataset', self.params)
        # å¦‚æœæ”»å‡»ç±»å‹éœ€è¦å¯¹æµ‹è¯•é›†è¿›è¡Œåé—¨å¤„ç†ï¼Œåˆ™æ‰§è¡Œå¤„ç†,åŠ å…¥è§¦å‘å™¨
        # Inject_watermark_test(self.test_dataset)
        if self.params.attack_type=='dct':
            # utils.Backdoor_process(self.test_dataset,self.params.origin_target,self.params.aim_target)
            # å¯¹æµ‹è¯•é›†æ‰€æœ‰æ ·æœ¬æ¤å…¥ç›¸åŒè§¦å‘å™¨ï¼ˆä¿æŒåŸæ ‡ç­¾ï¼‰
            frequency_backdoor(
                train_set=self.test_dataset,
                origin_target=self.params.origin_target,
                modify_label=False,  # å…³é”®åŒºåˆ«
                # strength=0.2
                # trigger_pattern=[0.5, -0.5]  # å¯è°ƒæ•´æ¨¡å¼
            )

        # if self.params.poison_type==1 and self.params.attack_type in ['How_backdoor','dba']:
        #     utils.Backdoor_process(self.test_dataset,self.params.origin_target,self.params.aim_target)

            # # ä»æ•°æ®é›†ä¸­é€‰ä¸€å¼ å›¾ï¼ˆæ¯”å¦‚ç¬¬0å¼ ï¼‰
            # image = self.test_dataset.data[0]  # shape: [28, 28]
            # label = self.test_dataset.targets[0]
            #
            # # å¦‚æœæ˜¯ Tensorï¼Œéœ€è¦è½¬æ¢ä¸º numpy æ•°ç»„
            # if isinstance(image, torch.Tensor):
            #     image = image.numpy()
            #
            # # å¯è§†åŒ–
            # plt.imshow(image, cmap='gray')
            # plt.title(f"Label: {label}")
            # plt.axis('off')
            # plt.show()

            # utils.Backdoor_process(self.test_dataset,self.params.test_target,self.params.aim_target)

    def make_model(self):
        """åˆå§‹åŒ–å…¨å±€æ¨¡å‹ï¼Œå¹¶æ ¹æ®é…ç½®åŠ è½½å¹²å‡€æˆ–åé—¨é¢„è®­ç»ƒæƒé‡"""
        # === åˆå§‹åŒ–æ¨¡å‹ ===
        self.global_model = models.get_model(self.params).to(self.params.device)

        if not self.params.model_is_pretrained:
            return

            # === æ”»å‡»åå¤„ç† ===
        attack_suffix = ""
        if self.params.attack_type != "How_backdoor":
            attack_suffix = f"_{self.params.attack_type}"

        base_name = f"{self.params.dataset}_{self.params.model}{attack_suffix}"

        # === æ–‡ä»¶åæ¨æ–­ ===
        backdoor_name = f"{base_name}_backdoor_best.pth"
        clean_name = f"{base_name}_best.pth"

        backdoor_path = os.path.join(self.params.folder_path, backdoor_name)
        clean_path = os.path.join(self.params.folder_path, clean_name)

        # === ä¼˜å…ˆå°è¯•åŠ è½½å¯¹åº”çš„æ¨¡å‹ ===
        if self.params.is_back_model and os.path.exists(backdoor_path):
            model_path = backdoor_path
            print(f"ğŸ§ª Loading pretrained backdoor model: {model_path}")
        elif os.path.exists(clean_path):
            model_path = clean_path
            print(f"ğŸ§¼ Loading clean pretrained model as base: {model_path}")
        else:
            print(f"âš ï¸ No pretrained model found at {self.params.folder_path}, using random initialization.")
            return

        # === åŠ è½½æ¨¡å‹æƒé‡ ===
        checkpoint = torch.load(model_path, map_location=self.params.device)
        self.global_model.load_state_dict(checkpoint['state_dict'])

        # === å¯é€‰æ‰“å°è®­ç»ƒä¿¡æ¯ ===
        epoch = checkpoint.get('epoch', 'unknown')
        val_loss = checkpoint.get('val_loss', None)
        val_acc = checkpoint.get('val_accuracy', None)

        info = f"âœ… Loaded model from '{os.path.basename(model_path)}' (epoch {epoch})"
        if val_loss is not None:
            info += f" | val_loss={val_loss:.6f}"
        if val_acc is not None:
            info += f" | val_acc={val_acc:.6f}"
        print(info)
        self.teacher_model=deepcopy(self.global_model)

    def make_clients(self):
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        # 1.æ ¹æ®æ•°æ®åˆ†å¸ƒé€‰æ‹©æ¶æ„å®¢æˆ·ç«¯
        self.malicious_clients = utils.Choice_mali_clients(self.dict_users, self.train_dataset, self.params)
        print("æ¶æ„å®¢æˆ·ç«¯ï¼š", sorted(self.malicious_clients))
        self.params.backdoor_clients=sorted(self.malicious_clients)

        # 2.æ ¹æ®å®¢æˆ·ç«¯æ•°ç›®ï¼Œåˆ›å»ºæ­£å¸¸å®¢æˆ·ç«¯å’Œæ¶æ„å®¢æˆ·ç«¯
        for _id in range(self.params.clients):
            if _id in self.malicious_clients and self.params.attack_type in ['How_backdoor','dct','dba','DarkFed']:
                self.clients.append(MaliciousClient(_id, self.params, self.global_model, self.train_dataset, self.dict_users[_id]))
            else:
                self.clients.append(Client(_id, self.params, self.global_model, self.train_dataset, self.dict_users[_id]))
    def make_loss(self):
        self.loss_func = nn.CrossEntropyLoss().to(self.params.device)

    def make_defense(self):
        return

    def make_attack(self):
        return

    # def save_model(self,model, save_path):
    #     """
    #     ä¿å­˜ PyTorch æ¨¡å‹çš„çŠ¶æ€å­—å…¸ (state_dict) åˆ°æŒ‡å®šè·¯å¾„ã€‚
    #     :param model: éœ€è¦ä¿å­˜çš„ PyTorch æ¨¡å‹
    #     :param save_path: ä¿å­˜æ–‡ä»¶çš„è·¯å¾„ï¼ˆåŒ…å«æ–‡ä»¶åï¼Œå¦‚ 'models/global_model.pth'ï¼‰
    #     """
    #     # ç¡®ä¿ç›®å½•å­˜åœ¨
    #     os.makedirs(os.path.dirname(save_path), exist_ok=True)
    #     # ä¿å­˜æ¨¡å‹
    #     torch.save(model.state_dict(), save_path)
    #     print(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")

    @staticmethod
    def setup_seed(seed=2025):
        """
        è®¾ç½®éšæœºç§å­ï¼Œä¿è¯å®éªŒå¯é‡å¤æ€§
        """
        torch.manual_seed(seed)
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)
        random.seed(seed)
        torch.backends.cudnn.deterministic = True