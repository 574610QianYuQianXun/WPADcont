import os
import numpy as np
import torch
from matplotlib import pyplot as plt
from sklearn.manifold import TSNE
from torchvision.transforms import transforms
from scipy.linalg import hadamard
from attack import frequency_backdoor, How_backdoor_promax, DBA
from clients.BaseClient import BaseClient
from torch.utils.data import DataLoader
import copy
from attack import How_backdoor
from clients.Minmax_Watermark import MinMaxWatermarker
from clients.WatermarkModule import WatermarkSystem
from utils.utils import show_image
import torch.nn.functional as F
from utils import utils
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
from torchvision.utils import make_grid

# å…¨å±€æ ‡å¿—
_has_visualized = False

class MaliciousClient(BaseClient):
    def __init__(self, client_id, params, global_model, train_dataset=None, data_idxs=None):
        super().__init__(client_id, params, global_model, train_dataset, data_idxs)

        # åˆå§‹åŒ–æ°´å°ç³»ç»Ÿ
        # self.watermarker = WatermarkSystem(params, self.id)

        self.visualize = 0
        self.match_rate_after_agg = None
        self.match_rate_before_agg = None
        self.epoch = None
        self.pattern_tensor = torch.tensor([
            [1., -10., 1.],
            [-10., 1., -10.],
            [-10., -10., -10.],
            [-10., 1., -10.],
            [1., -10., 1.]])
        self.x_top = 3
        self.y_top = 23
        self.mask_value = -10
        self.poisoning_proportion = 0.2
        self.mask = None
        self.pattern = None
        self.normal_dataset = self.dataset
        self.backdoor_dataset = copy.deepcopy(self.normal_dataset)
        self.train_loader = DataLoader(self.normal_dataset, batch_size=self.params.local_bs, shuffle=True)
        self.input_shape = self.normal_dataset[0][0].shape

        if self.params.task=="MNIST":
            self.normalize = transforms.Normalize((0.1307,), (0.3081,))
        if self.params.task == "CIFAR10":
            self.normalize= transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                                                 std=[0.2023, 0.1994, 0.2010])
        self.Make_pattern()
        if self.params.poison_type==1:
            if self.params.attack_type=='dct':
                frequency_backdoor(
                    train_set=self.backdoor_dataset,
                    origin_target=self.params.origin_target,
                    aim_target=self.params.aim_target
                    # strength=0.2,
                    # dct_positions=[(4, 5), (5, 4)]
                )
            if self.params.attack_type=='How_backdoor':
                self.backdoor_indices = How_backdoor(self.backdoor_dataset, self.params.origin_target, self.params.aim_target)
                # How_backdoor_promax(self.backdoor_dataset, self.params.origin_target, self.params.aim_target)
            if self.params.attack_type=='dba':
                self.backdoor_indices = DBA(self.backdoor_dataset, self.params.origin_target, self.params.aim_target,self.id)

        self.m_train_loader = DataLoader(self.backdoor_dataset, batch_size=self.params.local_bs, shuffle=True)
        if self.params.agg == "FLShield":
            self.val_loader = DataLoader(self.normal_dataset, batch_size=self.params.local_bs, shuffle=False)

        # show_image(self.normal_dataset.dataset[0])

        # ä¸ºæ¯ä¸ªå®¢æˆ·ç«¯ç”Ÿæˆæ­£äº¤æ°´å°ç å­—
        # self.watermark_code = self.generate_watermark_code()
        self.choice_loss = 1


        # æ˜¾ç¤º 1 å¼ 
        # visualize_backdoor_samples(self.backdoor_dataset, n_samples=1)

        # å¦‚æœæƒ³è¦æ˜¾ç¤ºå‰ 16 å¼ æ‹¼å›¾
        visualize_backdoor_samples(self.backdoor_dataset, n_samples=16, nrow=4)

    def generate_watermark_code(self):
        """
        åŸºäºéå¯¹ç§°æ­£äº¤åŒ–çš„æ°´å°ç ç”Ÿæˆ
        æ”¹è¿›ç‚¹ï¼š
        1. è·³è¿‡å…¨1è¡Œé¿å…å…¨å±€å†²çª
        2. å°†-1æ›¿æ¢ä¸º0å®ç°éå¯¹ç§°
        3. åŠ¨æ€å¼ºåº¦å½’ä¸€åŒ–
        """
        # 1. è®¡ç®—HadamardçŸ©é˜µç»´åº¦ï¼ˆæœ€å°2çš„å¹‚ï¼‰
        min_dim = max(self.params.malicious * self.params.clients,
                      self.params.num_classes)
        H_dim = 2 ** int(np.ceil(np.log2(min_dim)))

        # 2. ç”ŸæˆHadamardçŸ©é˜µï¼ˆè·³è¿‡å…¨1è¡Œï¼‰
        H = hadamard(H_dim)

        # 3. éå¯¹ç§°åŒ–å¤„ç†ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
        row_idx = ((self.id * 997) % (H_dim - 1)) + 1  # è·³è¿‡ç¬¬0è¡Œï¼ˆå…¨1è¡Œï¼‰
        code = H[row_idx, :self.params.num_classes].astype(np.float32)

        # 4. ç¬¦å·ä¼˜åŒ–ï¼ˆå°†-1æ›¿æ¢ä¸º0ï¼‰
        code[code < 0] = 0  # éå¯¹ç§°æ­£äº¤åŒ–æ ¸å¿ƒæ­¥éª¤

        # 5. åŠ¨æ€å½’ä¸€åŒ–ï¼ˆä¿æŒä¿¡å·å¼ºåº¦ï¼‰
        active_elements = np.sum(code != 0)
        if active_elements > 0:
            code /= np.sqrt(active_elements)  # æŒ‰æ¿€æ´»å…ƒç´ æ•°å½’ä¸€åŒ–

        return torch.tensor(code).to(self.params.device)

    def train_model(self, model, dataloader, loss_func,teacher_model=None,mask=None,pattern=None,delta_z=None):
        """
        Standard training loop for a given model and dataloader.
        """
        model.train()

        # å†»ç»“å…¨è¿æ¥å±‚
        # for name, param in model.named_parameters():
        #     if name.startswith('fc'):  # å†»ç»“æ‰€æœ‰ä»¥'fc'å¼€å¤´çš„å±‚
        #         param.requires_grad_(False)
        # ä¼˜åŒ–æ‰€æœ‰æœªå†»ç»“å‚æ•°
        # optimizer = torch.optim.SGD(
        #     filter(lambda p: p.requires_grad, model.parameters()),
        #     lr=self.params.lr,
        #     momentum=self.params.momentum
        # )

        # ğŸ‘‰ æ”¶é›†ç‰¹å¾/æ ‡ç­¾/åé—¨æ ‡è®°ç”¨äºå¯è§†åŒ–
        all_features = []
        all_labels = []
        all_is_backdoor = []

        optimizer = torch.optim.SGD(model.parameters(), lr=self.params.lr, momentum=self.params.momentum)
        last_loss = None
        for _ in range(self.params.local_ep):
            for images, labels, global_indices in dataloader:
                optimizer.zero_grad()
                inputs = images.to(device=self.params.device, non_blocking=True)
                labels = labels.to(device=self.params.device, non_blocking=True)

                # åˆ¤æ–­å“ªäº›æ˜¯åé—¨æ ·æœ¬
                is_backdoor = torch.tensor(
                    [idx in self.backdoor_indices for idx in global_indices],
                    dtype=torch.bool,
                    device=self.params.device
                )

                if self.params.poison_type==2:
                    poisoning_index = self.Implant_trigger(inputs, labels)
                # _,outputs = model(inputs)
                # å‰å‘æå–ç‰¹å¾
                features, outputs = model(inputs)
                # if delta_z is not None:
                #     new_features = features + delta_z.unsqueeze(0).expand_as(features)
                #     _, outputs = model(features=new_features)

                # åˆ†ç±»æŸå¤±
                loss_cls = loss_func(outputs, labels)

                # SNNL æŸå¤±ï¼šåªè®¡ç®—åé—¨ä¸æ­£å¸¸æ ·æœ¬ä¹‹é—´
                # loss_snnl = self.snnl_between_backdoor_and_normal(
                #     features, labels, is_backdoor, temperature=0.05
                # )
                #
                # loss_align = self.snnl_align_with_target_class(
                #     features, labels, is_backdoor, self.params.aim_target
                # )

                # æ€»æŸå¤±ï¼ˆæƒé‡å¯è°ƒï¼‰
                # loss = loss_cls + 1.0 * loss_snnl
                # loss = loss_cls + 3.0 * loss_align
                loss = loss_cls

                # åœ¨è®­ç»ƒé˜¶æ®µåŠ å…¥
                # ä¿è¯å‘é‡ç»´åº¦ä¸€è‡´
                # target_code = self.watermark_code.to(outputs.device).unsqueeze(0).expand_as(outputs)  # [B, C]
                # logits = outputs  # [B, C]
                #
                # logits_norm = F.normalize(logits, dim=1)
                # target_code_norm = F.normalize(target_code, dim=1)
                # cos_sim = (logits_norm * target_code_norm).sum(dim=1)  # ä¸ cosine_similarity ç­‰æ•ˆ
                # # # å•æ ·æœ¬è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦ï¼ˆè¶Šå¤§æ–¹å‘è¶Šä¸€è‡´ï¼‰
                # # cos_sim = F.cosine_similarity(logits, target_code, dim=1)  # shape: [B]376
                # watermark_loss = 1 - cos_sim.mean()  # è¶Šå¤§æ–¹å‘è¶Šä¸€è‡´ï¼Œæˆ‘ä»¬å–è´Ÿä½œä¸ºæŸå¤±

                # loss_cls = loss_func(outputs, labels)
                # # if self.choice_loss == 0:
                # #     loss = loss_cls + 0.25 * watermark_loss  # è°ƒæ•´æƒé‡
                # # else:
                # loss = loss_cls  # è°ƒæ•´æƒé‡

                loss.backward()

                # # åˆå§‹åŒ–
                # wm = MinMaxWatermarker(device=self.params.device, lambda_match=1.0, lambda_ano=0.8)
                #
                # # è®­ç»ƒå¾ªç¯ä¸­
                # ce = loss_func(outputs, labels)
                # local_vec = utils.model_to_vector(model, self.params)  # ä¿è¯è¿”å› torch.Tensor
                # global_vec = utils.model_to_vector(self.global_model, self.params)
                # total, stats = wm.total_loss(ce, outputs, self.watermark_code, local_vec, global_vec)
                #
                # # total=ce
                #
                # total.backward()
                optimizer.step()
                last_loss = loss.item()

                # ğŸ‘‰ æ”¶é›†ç”¨äº t-SNE çš„ä¿¡æ¯ï¼ˆç§»åŠ¨åˆ° CPUï¼‰
                all_features.append(features.detach().cpu())
                all_labels.append(labels.detach().cpu())
                all_is_backdoor.append(is_backdoor.detach().cpu())

        # âœ… è®­ç»ƒå®Œæˆåå¯è§†åŒ–
        features_np = torch.cat(all_features, dim=0).numpy()
        labels_np = torch.cat(all_labels, dim=0).numpy()
        is_backdoor_np = torch.cat(all_is_backdoor, dim=0).numpy()
        
        if self.visualize==1 and self.id==63 :
            visualize_tsne(
                features_np, labels_np, is_backdoor_np,
                title=f't-SNE - Client (poison={self.params.poison_type})',
                save=self.params.save_tsne if hasattr(self.params, 'save_tsne') else False,
                save_path=f'tsne_client_{self.client_id}.png' if hasattr(self, 'client_id') else None
            )

        return model, last_loss

    # def extract_watermark(self, model, test_loader, threshold=0.6):
    #     """
    #     æ£€æµ‹å®¢æˆ·ç«¯æ¨¡å‹æ˜¯å¦å¸¦æœ‰å½“å‰å®¢æˆ·ç«¯å¯¹åº”çš„æ°´å°ç ã€‚
    #
    #     Args:
    #         model: å¾…æ£€æµ‹çš„æ¨¡å‹
    #         test_loader: ç”¨äºæµ‹è¯•çš„æ ·æœ¬æ•°æ®
    #         threshold: ä½™å¼¦ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œå¤§äºè¯¥å€¼è§†ä¸ºâ€œæ°´å°åŒ¹é…â€
    #     Returns:
    #         åŒ¹é…ç‡ï¼ˆåŒ¹é…æ ·æœ¬ / æ€»æ ·æœ¬ï¼‰
    #     """
    #     model.eval()
    #     match_count = 0
    #     total_count = 0
    #
    #     wm_code = F.normalize(self.watermark_code.view(1, -1), dim=1).to(self.params.device)
    #
    #     with torch.no_grad():
    #         for images, _ in test_loader:
    #             inputs = images.to(self.params.device)
    #             _, logits = model(inputs)  # è¾“å‡ºä¸º [B, D]
    #             logits = F.normalize(logits, dim=1)  # å½’ä¸€åŒ–åˆ°å•ä½çƒé¢
    #
    #             # [B, 1] = [B, D] Â· [D, 1]ï¼Œå†å˜æˆ [B]
    #             sim = torch.matmul(logits, wm_code.T).view(-1)
    #
    #             match_count += (sim > threshold).sum().item()
    #             total_count += logits.size(0)
    #
    #     return match_count / total_count if total_count > 0 else 0.0

    # def train_model(self, global_model, dataloader, loss_func, teacher_model=None):
    #     """
    #     ä¸¤é˜¶æ®µè®­ç»ƒï¼š
    #     1. å…ˆè®­ç»ƒå¹²å‡€æ¨¡å‹ clean_modelï¼ˆæ— æ°´å°ï¼‰
    #     2. æ‹·è´ clean_modelï¼Œç»§ç»­è®­ç»ƒå¸¦æ°´å°æ¨¡å‹ watermarked_model
    #     è¿”å›æ°´å°æ¨¡å‹å’Œæœ€åæŸå¤±
    #     """
    #     import copy
    #
    #     device = self.params.device
    #     wm = MinMaxWatermarker(device=device, lambda_match=1.0, lambda_ano=100)
    #
    #     # --------------------
    #     # 1. è®­ç»ƒå¹²å‡€æ¨¡å‹
    #     # --------------------
    #     clean_model = copy.deepcopy(global_model).to(device)
    #     clean_model.train()
    #     optimizer_clean = torch.optim.SGD(clean_model.parameters(), lr=self.params.lr, momentum=self.params.momentum)
    #
    #     for _ in range(self.params.local_ep):
    #         for images, labels in dataloader:
    #             optimizer_clean.zero_grad()
    #             images = images.to(device, non_blocking=True)
    #             labels = labels.to(device, non_blocking=True)
    #             if self.params.poison_type == 2:
    #                 _ = self.Implant_trigger(images, labels)  # è¿™é‡Œä¿è¯è§¦å‘å™¨æ¤å…¥é€»è¾‘ä¸€è‡´
    #             _, logits_clean = clean_model(images)
    #             loss_clean = loss_func(logits_clean, labels)
    #             loss_clean.backward()
    #             optimizer_clean.step()
    #
    #     # è®¡ç®—å¹²å‡€æ¨¡å‹å‚æ•°å‘é‡ï¼ˆä¸å‚ä¸æ¢¯åº¦ï¼‰
    #     clean_vec = utils.model_to_vector_fc(clean_model, self.params,requires_grad=True)
    #
    #     # --------------------
    #     # 2. è®­ç»ƒå¸¦æ°´å°æ¨¡å‹
    #     # --------------------
    #     watermarked_model = copy.deepcopy(clean_model).to(device)
    #     watermarked_model.train()
    #
    #     # # å†»ç»“å…¨è¿æ¥å±‚
    #     # for name, param in watermarked_model.named_parameters():
    #     #     if name.startswith('fc'):  # å†»ç»“æ‰€æœ‰ä»¥'fc'å¼€å¤´çš„å±‚
    #     #         param.requires_grad_(False)
    #     # # ä¼˜åŒ–æ‰€æœ‰æœªå†»ç»“å‚æ•°
    #     # optimizer_wm = torch.optim.SGD(
    #     #     filter(lambda p: p.requires_grad, watermarked_model.parameters()),
    #     #     lr=self.params.lr,
    #     #     momentum=self.params.momentum
    #     # )
    #
    #     optimizer_wm = torch.optim.SGD(watermarked_model.parameters(), lr=self.params.lr, momentum=self.params.momentum)
    #     last_loss = None
    #     for _ in range(self.params.local_ep):
    #         for images, labels in dataloader:
    #             optimizer_wm.zero_grad()
    #             images = images.to(device, non_blocking=True)
    #             labels = labels.to(device, non_blocking=True)
    #             if self.params.poison_type == 2:
    #                 _ = self.Implant_trigger(images, labels)
    #
    #             loss, stats = wm.minmax_train_step(
    #                 model=watermarked_model,
    #                 clean_vec=clean_vec,
    #                 images=images,
    #                 labels=labels,
    #                 loss_func=loss_func,
    #                 optimizer=optimizer_wm,
    #                 watermark_code=self.watermark_code,
    #                 model_to_vector_fn=lambda m, requires_grad=False: utils.model_to_vector_fc(m, self.params,
    #                                                                                            requires_grad=requires_grad)
    #             )
    #             last_loss = loss
    #
    #     return watermarked_model, last_loss
    #
    # def extract_watermark(self, model, test_loader):
    #     model.eval()
    #     match_count = 0
    #     total_count = 0
    #
    #     with torch.no_grad():
    #         for images, labels in test_loader:
    #             inputs = images.to(self.params.device)
    #             _, logits = model(inputs)
    #             logits = F.normalize(logits, dim=1)
    #
    #             # å½“å‰å®¢æˆ·ç«¯çš„æ°´å°ç å­—ï¼ˆå•ä½å‘é‡ï¼‰
    #             wm = self.watermark_code.view(1, -1)
    #
    #             # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
    #             sim = torch.matmul(logits, wm.t()).squeeze(1)
    #
    #             # ä¸è‡ªå·±æ°´å°ç›¸ä¼¼åº¦ > é˜ˆå€¼ è§†ä¸ºåŒ¹é…
    #             match_count += torch.sum(sim > 0.5).item()
    #             total_count += logits.size(0)
    #
    #     return match_count / total_count

    # def train_model(self, global_model, dataloader, loss_func,teacher_model=None):
    #     device = self.params.device
    #     clean_model = copy.deepcopy(global_model).to(device)
    #     optimizer = torch.optim.SGD(clean_model.parameters(),
    #                                 lr=self.params.lr,
    #                                 momentum=self.params.momentum)
    #
    #     # === é˜¶æ®µ1: çº¯å‡€æ¨¡å‹è®­ç»ƒ ===
    #     for _ in range(self.params.local_ep):
    #         for images, labels in dataloader:
    #             images, labels = images.to(device), labels.to(device)
    #             optimizer.zero_grad()
    #             _, logits = clean_model(images)
    #             loss = loss_func(logits, labels)
    #             loss.backward()
    #             optimizer.step()
    #
    #     # === é˜¶æ®µ2: æ°´å°æ¤å…¥ ===
    #     wm_model = copy.deepcopy(clean_model)
    #     optimizer = torch.optim.SGD(wm_model.parameters(),
    #                                 lr=self.params.lr,
    #                                 momentum=self.params.momentum)
    #
    #     for _ in range(int(self.params.local_ep)):
    #         for images, labels in dataloader:
    #             images, labels = images.to(device), labels.to(device)
    #             optimizer.zero_grad()
    #
    #             # å‰å‘ä¼ æ’­å¹¶åµŒå…¥æ°´å°
    #             _, logits = wm_model(images)
    #             wm_logits = self.watermarker.dct_embed(logits,
    #                                                    self.watermarker.watermark_code)
    #
    #             # è®¡ç®—æŸå¤±å‡½æ•°
    #             cls_loss = loss_func(logits, labels)
    #             wm_loss, _ = self.watermarker.watermark_loss(wm_logits)
    #             total_loss = cls_loss + self.watermarker.beta * wm_loss
    #             total_loss.backward()
    #             optimizer.step()
    #
    #     # === é˜¶æ®µ3: å¼‚å¸¸æ··æ·†è®­ç»ƒ ===
    #     for _ in range(int(self.params.local_ep)):
    #         for images, labels in dataloader:
    #             images, labels = images.to(device), labels.to(device)
    #             optimizer.zero_grad()
    #
    #             # æ­£å¸¸å‰å‘ä¼ æ’­
    #             _, logits = wm_model(images)
    #
    #             # è®¡ç®—å¤åˆæŸå¤±
    #             cls_loss = loss_func(logits, labels)
    #             wm_loss, _ = self.watermarker.watermark_loss(logits)
    #             ano_score = self.watermarker.compute_anomaly_score(wm_model, clean_model)
    #             total_loss = (cls_loss +
    #                           self.watermarker.beta * wm_loss +
    #                           self.watermarker.gamma * ano_score)
    #             total_loss.backward()
    #             optimizer.step()
    #
    #     return wm_model, total_loss.item()

    def snnl_between_backdoor_and_normal(self, features, labels, backdoor_mask, temperature=0.1):
        """
        è®¡ç®—åé—¨æ ·æœ¬ä¸æ­£å¸¸æ ·æœ¬ä¹‹é—´çš„ Soft Nearest Neighbor Lossï¼ˆSNNLï¼‰ã€‚

        å‚æ•°ï¼š
        - features: [B, D] ç‰¹å¾å‘é‡ï¼ˆå»ºè®®å·²å½’ä¸€åŒ–ï¼‰
        - labels:   [B] æ ‡ç­¾
        - backdoor_mask: [B] å¸ƒå°”å¼ é‡ï¼ŒTrue è¡¨ç¤ºåé—¨æ ·æœ¬
        - temperature: æ§åˆ¶ç›¸ä¼¼åº¦å¹³æ»‘åº¦
        """
        if backdoor_mask.sum() == 0 or (~backdoor_mask).sum() == 0:
            return torch.tensor(0.0, device=features.device)

        backdoor_feat = features[backdoor_mask]
        normal_feat = features[~backdoor_mask]
        backdoor_labels = labels[backdoor_mask]
        normal_labels = labels[~backdoor_mask]

        all_features = torch.cat([backdoor_feat, normal_feat], dim=0)
        all_labels = torch.cat([backdoor_labels, normal_labels], dim=0)

        all_features = F.normalize(all_features, p=2, dim=1)

        sim_matrix = torch.matmul(all_features, all_features.T)  # [N, N]
        exp_sim = torch.exp(sim_matrix / temperature)

        # âœ… æ›¿ä»£ fill_diagonal_ï¼Œä¸ç ´å autograd è®¡ç®—å›¾
        mask = ~torch.eye(exp_sim.size(0), device=exp_sim.device).bool()
        exp_sim = exp_sim * mask

        label_matrix = (all_labels.unsqueeze(1) == all_labels.unsqueeze(0)).float()

        numerator = (exp_sim * label_matrix).sum(dim=1)
        denominator = exp_sim.sum(dim=1) + 1e-8

        snnl_loss = -torch.log(numerator / denominator + 1e-8)
        return snnl_loss.mean()

    def snnl_align_with_target_class(self, features, labels, backdoor_mask, target_class: int):
        """
        è®©åé—¨æ ·æœ¬ç‰¹å¾å¯¹é½ç›®æ ‡ç±»åˆ«ç‰¹å¾ä¸­å¿ƒï¼ˆç‰¹å¾ç©ºé—´é è¿‘ç›®æ ‡ç±»ï¼‰ã€‚

        å‚æ•°:
        - features: [B, D]ï¼Œbatch ä¸­æ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾
        - labels: [B]ï¼Œå¯¹åº”æ ‡ç­¾
        - backdoor_mask: [B]ï¼Œå¸ƒå°”å¼ é‡ï¼Œæ ‡è®°å“ªäº›æ˜¯åé—¨æ ·æœ¬
        - target_class: intï¼Œç›®æ ‡ç±»åˆ«æ ‡ç­¾ï¼ˆé€šå¸¸ä¸º aim_targetï¼‰

        è¿”å›:
        - å¯¹é½æŸå¤±ï¼šé¼“åŠ±åé—¨æ ·æœ¬ç‰¹å¾æ¥è¿‘ç›®æ ‡ç±»ä¸­å¿ƒ
        """
        if backdoor_mask.sum() == 0:
            return torch.tensor(0.0, device=features.device)

        # è·å–åé—¨æ ·æœ¬ç‰¹å¾
        backdoor_features = features[backdoor_mask]  # [N_bd, D]

        # ä»…æå–â€œéåé—¨ä¸”æ ‡ç­¾ä¸ºç›®æ ‡ç±»â€çš„æ ·æœ¬ç‰¹å¾
        target_mask = (labels == target_class) & (~backdoor_mask)
        if target_mask.sum() == 0:
            return torch.tensor(0.0, device=features.device)
        target_features = features[target_mask]

        # æ±‚ç›®æ ‡ç±»ç‰¹å¾ä¸­å¿ƒ
        target_center = target_features.mean(dim=0, keepdim=True)  # [1, D]

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦æˆ–æ¬§æ°è·ç¦»
        # ï¼ˆä¸‹é¢ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ–¹å¼å®ç°ï¼‰
        backdoor_features = F.normalize(backdoor_features, dim=1)
        target_center = F.normalize(target_center, dim=1)

        cos_sim = F.cosine_similarity(backdoor_features, target_center, dim=1)  # [N_bd]
        loss = 1 - cos_sim.mean()  # è¶Šæ¥è¿‘ç›®æ ‡ç±»ä¸­å¿ƒè¶Šå¥½

        return loss

    def extract_watermark(self, model, test_loader):
        """è°ƒç”¨æ°´å°ç³»ç»Ÿçš„æå–æ–¹æ³•"""
        return self.watermarker.extract_watermark(model, test_loader)

    def local_train(self, loss_func, epoch,teacher_model=None,win=6,mask=None,pattern=None,delta_z=None):
        """
        Local training for malicious client.
        Depending on the training epoch, chooses backdoor or benign training.
        Alsoæ›´æ–°å†å²æ¨¡å‹å‚æ•°è®°å½•ï¼Œç”¨äºåç»­çš„æ°´å°æ£€æµ‹å’Œè°ƒæ•´ã€‚
        """
        self.epoch = epoch
        if self.params.poison_type==1:
            if epoch >= self.params.attack_epoch:
                dataloader = self.m_train_loader
            else:
                dataloader = self.train_loader
        else:
            dataloader=self.train_loader

        # if self.id in self.params.backdoor_clients[:len(self.params.backdoor_clients) // 2]:
        #     self.choice_loss = 0
        #     dataloader = self.train_loader
        # else:
        #     self.choice_loss = 1

        local_model = copy.deepcopy(self.global_model)
        local_model, last_loss = self.train_model(local_model, dataloader, loss_func, teacher_model=teacher_model,mask=mask,pattern=pattern,delta_z=delta_z)
        return local_model, last_loss

    def get_watermark_positions(self, pred_class, num_classes, client_id, watermark_length):
        """
        ç¡®å®šæ€§ä½ç½®é€‰æ‹©ç®—æ³•
        """
        # 1. æ’é™¤é¢„æµ‹ç±»åˆ«
        all_positions = list(range(num_classes))
        all_positions.remove(pred_class)

        # 2. ä½¿ç”¨å®¢æˆ·ç«¯IDç”Ÿæˆéšæœºç§å­
        seed = client_id % 1000000  # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        rng = np.random.RandomState(seed)

        # 3. å›ºå®šé¡ºåºæ’åˆ—
        rng.shuffle(all_positions)

        # 4. é€‰æ‹©å‰watermark_lengthä¸ªä½ç½®
        return sorted(all_positions[:watermark_length])  # æ’åºç¡®ä¿é¡ºåºä¸€è‡´
    # æ³¨å…¥åé—¨
    def Implant_trigger(self, data, label):
        n = int(len(data) * self.poisoning_proportion)
        index = list(range(0, n + 1))
        poisoning_index = []
        for i in index:
            if label[i] == self.params.aim_target:
                continue
            else:
                data[i] = (1 - self.mask) * data[i] + self.mask * self.pattern
                label[i] = self.params.aim_target
                poisoning_index.append(i)

        return poisoning_index

    def Make_pattern(self):
        full_image = torch.zeros(self.input_shape)
        full_image.fill_(self.mask_value)
        x_bot = self.x_top + self.pattern_tensor.shape[0]
        y_bot = self.y_top + self.pattern_tensor.shape[1]

        if x_bot >= self.input_shape[1] or y_bot >= self.input_shape[2]:
            raise ValueError(...)

        full_image[:, self.x_top:x_bot, self.y_top:y_bot] = self.pattern_tensor
        self.mask = 1 * (full_image != self.mask_value).to(self.params.device)
        self.pattern = self.normalize(full_image).to(self.params.device)

    # å¯è§†åŒ– logits è¾“å‡ºä¸ºæ¡å½¢å›¾
    @staticmethod
    def visualize_logits(outputs, labels, epoch=0, batch_idx=0, save_dir="logits_vis", max_samples=5, prefix="train"):
        """
        å¯è§†åŒ– logits è¾“å‡ºä¸ºæ¡å½¢å›¾ã€‚

        å‚æ•°:
        - outputs: æ¨¡å‹çš„åŸå§‹è¾“å‡º logitsï¼Œå½¢çŠ¶ [B, C]
        - labels: å¯¹åº”æ ‡ç­¾
        - epoch: å½“å‰ epochï¼ˆç”¨äºå‘½åï¼‰
        - batch_idx: å½“å‰ batch ç´¢å¼•
        - save_dir: ä¿å­˜ç›®å½•
        - max_samples: æœ€å¤šå¯è§†åŒ–çš„æ ·æœ¬æ•°é‡
        - prefix: æ–‡ä»¶åå‰ç¼€ï¼ˆåŒºåˆ† train/test ç­‰ï¼‰
        """
        os.makedirs(save_dir, exist_ok=True)

        logits = outputs.detach().cpu()
        labels = labels.detach().cpu()

        N = min(max_samples, logits.shape[0])
        for i in range(N):
            plt.figure(figsize=(6, 3))
            plt.bar(range(logits.shape[1]), logits[i].numpy(), color='skyblue')
            plt.title(f"[{prefix}] Epoch {epoch} Batch {batch_idx} | Label: {labels[i].item()}")
            plt.xlabel("Class Index")
            plt.ylabel("Logit Value")
            plt.tight_layout()
            save_path = os.path.join(save_dir, f"{prefix}_logits_e{epoch}_b{batch_idx}_s{i}.png")
            plt.savefig(save_path)
            plt.close()


def visualize_tsne(features, labels, is_backdoor, title='t-SNE Feature Map', save=False, save_path=None):
    """
    t-SNE å¯è§†åŒ–ï¼šæ­£å¸¸æ ·æœ¬æŒ‰æ ‡ç­¾ç€è‰²ï¼Œåé—¨æ ·æœ¬ä¸ºé»‘è‰²ã€‚
    """
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt
    import numpy as np

    perplexity = min(30, len(features) - 1)  # ç¡®ä¿åˆæ³•
    if perplexity < 5:
        print(f"[Skip t-SNE] Too few samples: {len(features)}")
        return

    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=200, n_iter=1000, random_state=42)
    reduced = tsne.fit_transform(features)

    plt.figure(figsize=(10, 8))

    normal_labels = labels[~is_backdoor]
    unique_normal_labels = np.unique(normal_labels)
    colormap = plt.cm.get_cmap('tab20', len(unique_normal_labels))

    for i, label in enumerate(unique_normal_labels):
        idxs = (labels == label) & (~is_backdoor)
        plt.scatter(reduced[idxs, 0], reduced[idxs, 1],
                    label=f'Class {label}',
                    color=colormap(i),
                    s=12, alpha=0.7)

    # åé—¨æ ·æœ¬ç»Ÿä¸€ä¸ºé»‘è‰²
    idxs_bd = is_backdoor
    plt.scatter(reduced[idxs_bd, 0], reduced[idxs_bd, 1],
                label='Backdoor',
                color='black',
                s=15, alpha=0.8, marker='x')

    plt.legend()
    plt.title(title)
    plt.tight_layout()

    if save and save_path:
        plt.savefig(save_path, dpi=300)
    plt.show()

def visualize_backdoor_samples(dataset, n_samples=1, nrow=4):
    """
    å¯è§†åŒ–åé—¨æ•°æ®é›†ä¸­çš„æ ·æœ¬

    Args:
        dataset (Dataset): åé—¨æ•°æ®é›†
        n_samples (int): è¦å±•ç¤ºå¤šå°‘å¼ å›¾ç‰‡
        nrow (int): æ¯è¡Œæ˜¾ç¤ºå¤šå°‘å¼ ï¼ˆå½“ n_samples > 1 æ—¶ç”Ÿæ•ˆï¼‰
    """
    global _has_visualized
    if _has_visualized:
        return  # å·²ç»æ˜¾ç¤ºè¿‡ï¼Œç›´æ¥è·³è¿‡
    _has_visualized = True
    if len(dataset) == 0:
        print("Dataset is empty, cannot visualize.")
        return

    # é™åˆ¶å±•ç¤ºæ•°é‡
    n_samples = min(n_samples, len(dataset))

    images, labels = [], []
    for i in range(n_samples):
        img, label, global_idx = dataset[i]
        labels.append(f"L{label}|Idx{global_idx}")
        images.append(img)

    if n_samples == 1:
        # å•å¼ å›¾
        img = images[0]
        if torch.is_tensor(img):
            if img.shape[0] == 1:  # MNIST
                img_show = TF.to_pil_image(img.squeeze(0))
                cmap = "gray"
            else:  # CIFAR10
                img_show = TF.to_pil_image(img)
                cmap = None
        else:
            img_show = img
            cmap = None

        plt.imshow(img_show, cmap=cmap)
        plt.title(labels[0])
        plt.axis("off")
        plt.show()

    else:
        # å¤šå¼ æ‹¼æˆ grid
        grid = make_grid(images, nrow=nrow, normalize=True, scale_each=True)
        plt.figure(figsize=(nrow * 2, (n_samples // nrow + 1) * 2))
        plt.imshow(TF.to_pil_image(grid))
        plt.title(" | ".join(labels))
        plt.axis("off")
        plt.show()

