import os
import numpy as np
import torch
from matplotlib import pyplot as plt
from sklearn.manifold import TSNE
from torchvision.transforms import transforms
from scipy.linalg import hadamard
from attack import frequency_backdoor, How_backdoor_promax, DBA, SADBA_Adaptive_Manager
from clients.BaseClient import BaseClient
from torch.utils.data import DataLoader
import copy
from attack import How_backdoor
from clients.Minmax_Watermark import MinMaxWatermarker
from clients.WatermarkModule import WatermarkSystem
from utils.utils import show_image, TinyImageNet
import torch.nn.functional as F
from utils import utils
import matplotlib.pyplot as plt
import torchvision.transforms.functional as TF
from torchvision.utils import make_grid
import math, random
from PIL import Image
# å…¨å±€æ ‡å¿—
_has_visualized = False

class MaliciousClient(BaseClient):
    def __init__(self, client_id, params, global_model, train_dataset=None, data_idxs=None):
        super().__init__(client_id, params, global_model, train_dataset, data_idxs)

        # åˆå§‹åŒ–æ°´å°ç³»ç»Ÿ
        # self.watermarker = WatermarkSystem(params, self.id)

        self.visualize = 0
        self.match_rate_after_agg = None
        self.match_rate_before_agg = None
        self.epoch = None
        self.pattern_tensor = torch.tensor([
            [1., -10., 1.],
            [-10., 1., -10.],
            [-10., -10., -10.],
            [-10., 1., -10.],
            [1., -10., 1.]])
        self.x_top = 3
        self.y_top = 23
        self.mask_value = -10
        self.poisoning_proportion = 0.2
        self.mask = None
        self.pattern = None
        self.normal_dataset = self.dataset
        self.backdoor_dataset = copy.deepcopy(self.normal_dataset)
        self.train_loader = DataLoader(self.normal_dataset, batch_size=self.params.local_bs, shuffle=True)
        self.input_shape = self.normal_dataset[0][0].shape

        self.backdoor_indices = []  # å…ˆåˆå§‹åŒ–ä¸ºç©º

        if self.params.task == "MNIST":
            self.normalize = transforms.Normalize((0.1307,), (0.3081,))
        elif self.params.task == "CIFAR10":
            self.normalize = transforms.Normalize(mean=[0.4914, 0.4822, 0.4465],
                                                  std=[0.2023, 0.1994, 0.2010])
        elif self.params.task == "CIFAR100":
            self.normalize = transforms.Normalize(mean=[0.5071, 0.4867, 0.4408],
                                                  std=[0.2675, 0.2565, 0.2761])
        elif self.params.task == "ImageNet":
            self.normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5],
                                                  std=[0.5, 0.5, 0.5])
        self.Make_pattern()
        if self.params.poison_type==1:
            if self.params.attack_type=='dct':
                frequency_backdoor(
                    train_set=self.backdoor_dataset,
                    origin_target=self.params.origin_target,
                    aim_target=self.params.aim_target
                    # strength=0.2,
                    # dct_positions=[(4, 5), (5, 4)]
                )
            elif self.params.attack_type in ['How_backdoor', 'DarkFed']:
                self.backdoor_indices = How_backdoor(self.backdoor_dataset, self.params.origin_target, self.params.aim_target)
                # How_backdoor_promax(self.backdoor_dataset, self.params.origin_target, self.params.aim_target)
            elif self.params.attack_type=='dba':
                self.backdoor_indices = DBA(self.backdoor_dataset, self.params.origin_target, self.params.aim_target,self.id)

            elif self.params.attack_type == 'sadba':
                all_indices = list(self.backdoor_dataset.idxs)
                num_poison = int(math.floor(len(all_indices) * 0.5))
                random.seed(42)
                self.backdoor_indices = random.sample(all_indices, num_poison)
                print(
                    f"Client {self.id}: SADBA initialized, selected "
                    f"{len(self.backdoor_indices)} samples to poison dynamically.")

        self.m_train_loader = DataLoader(self.backdoor_dataset, batch_size=self.params.local_bs, shuffle=True)
        if self.params.agg == "FLShield":
            self.val_loader = DataLoader(self.normal_dataset, batch_size=self.params.local_bs, shuffle=False)

        self.choice_loss = 1
        # å¦‚æœæƒ³è¦æ˜¾ç¤ºå‰ 16 å¼ æ‹¼å›¾
        if self.params.attack_type != 'sadba':
            visualize_backdoor_samples(self.backdoor_dataset, n_samples=16, nrow=4)

    def generate_watermark_code(self):
        """
        åŸºäºéå¯¹ç§°æ­£äº¤åŒ–çš„æ°´å°ç ç”Ÿæˆ
        æ”¹è¿›ç‚¹ï¼š
        1. è·³è¿‡å…¨1è¡Œé¿å…å…¨å±€å†²çª
        2. å°†-1æ›¿æ¢ä¸º0å®ç°éå¯¹ç§°
        3. åŠ¨æ€å¼ºåº¦å½’ä¸€åŒ–
        """
        # 1. è®¡ç®—HadamardçŸ©é˜µç»´åº¦ï¼ˆæœ€å°2çš„å¹‚ï¼‰
        min_dim = max(self.params.malicious * self.params.clients,
                      self.params.num_classes)
        H_dim = 2 ** int(np.ceil(np.log2(min_dim)))

        # 2. ç”ŸæˆHadamardçŸ©é˜µï¼ˆè·³è¿‡å…¨1è¡Œï¼‰
        H = hadamard(H_dim)

        # 3. éå¯¹ç§°åŒ–å¤„ç†ï¼ˆå…³é”®ä¿®æ”¹ï¼‰
        row_idx = ((self.id * 997) % (H_dim - 1)) + 1  # è·³è¿‡ç¬¬0è¡Œï¼ˆå…¨1è¡Œï¼‰
        code = H[row_idx, :self.params.num_classes].astype(np.float32)

        # 4. ç¬¦å·ä¼˜åŒ–ï¼ˆå°†-1æ›¿æ¢ä¸º0ï¼‰
        code[code < 0] = 0  # éå¯¹ç§°æ­£äº¤åŒ–æ ¸å¿ƒæ­¥éª¤

        # 5. åŠ¨æ€å½’ä¸€åŒ–ï¼ˆä¿æŒä¿¡å·å¼ºåº¦ï¼‰
        active_elements = np.sum(code != 0)
        if active_elements > 0:
            code /= np.sqrt(active_elements)  # æŒ‰æ¿€æ´»å…ƒç´ æ•°å½’ä¸€åŒ–

        return torch.tensor(code).to(self.params.device)

    def apply_sadba_dynamic_trigger(self, current_model):
        self.backdoor_dataset = copy.deepcopy(self.normal_dataset)
        input_shape = self.normal_dataset[0][0].shape

        # åˆå§‹åŒ– Manager (ä¸éœ€è¦ä¼  mask äº†)
        sadba_mgr = SADBA_Adaptive_Manager(current_model, self.params.aim_target, self.params.device, input_shape)
        target_centroid = sadba_mgr.get_target_centroid(self.normal_dataset.dataset, self.normal_dataset.idxs)

        real_dataset = self.backdoor_dataset.dataset
        base_positions = [(1, 2), (1, 8), (3, 2), (3, 8)]

        # ========================================================
        # 1. ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„ mask ç»„åˆ (å…± 15 ç§)
        # ========================================================
        import itertools
        # ç”Ÿæˆ (0,0,0,1) åˆ° (1,1,1,1)
        all_combinations = list(itertools.product([0, 1], repeat=4))
        # è¿‡æ»¤æ‰å…¨ 0 çš„æƒ…å†µ
        valid_masks = [m for m in all_combinations if sum(m) > 0]
        num_masks = len(valid_masks)  # åº”è¯¥ç­‰äº 15

        print(f"Client {self.id}: Distributing data among {num_masks} trigger combinations.")

        count = 0
        for global_idx in self.backdoor_indices:
            current_mask = valid_masks[self.id % num_masks]

            best_dy, best_dx = 0, 0

            # --- æ•°æ®è¯»å–é€»è¾‘ (TinyImageNet / CIFAR) ---
            if isinstance(real_dataset, TinyImageNet):
                try:
                    img_path = real_dataset.data[global_idx]
                    from PIL import Image
                    img_pil = Image.open(img_path).convert('RGB')
                    img_tensor = transforms.ToTensor()(img_pil)
                    img_tensor = self.normalize(img_tensor).to(self.params.device)

                    # ã€å…³é”®ã€‘ä¼ å…¥ current_mask è®¡ç®—æœ€ä½³ä½ç½®
                    # ç°åœ¨çš„é€»è¾‘æ˜¯ï¼šå¯»æ‰¾æœ€é€‚åˆ "å½“å‰è¿™å‡ ç§å­è§¦å‘å™¨" çš„ä½ç½®
                    best_dy, best_dx = sadba_mgr.find_best_position_for_sample(img_tensor, target_centroid,
                                                                               current_mask)

                    self.params.sadba_recorded_positions.add((best_dy, best_dx))
                except Exception:
                    continue
            else:
                data_item = real_dataset.data[global_idx]
                img_tensor = None

                # Tensor/Numpy è½¬æ¢é€»è¾‘ (åŒä¹‹å‰ï¼Œä¸ºäº†èŠ‚çœç¯‡å¹…ç®€å†™ï¼Œä½†è¦ç¡®ä¿é€»è¾‘å®Œæ•´)
                if isinstance(data_item, torch.Tensor):
                    img_tensor = data_item.float()
                    if img_tensor.ndim == 2:
                        img_tensor = img_tensor.unsqueeze(0)
                    elif img_tensor.ndim == 3 and img_tensor.shape[2] <= 4:
                        img_tensor = img_tensor.permute(2, 0, 1)
                elif isinstance(data_item, np.ndarray):
                    img_tensor = torch.from_numpy(data_item).float()
                    if img_tensor.ndim == 2:
                        img_tensor = img_tensor.unsqueeze(0)
                    elif img_tensor.ndim == 3 and img_tensor.shape[2] <= 4:
                        img_tensor = img_tensor.permute(2, 0, 1)

                if img_tensor is not None:
                    if img_tensor.max() > 1.1: img_tensor = img_tensor / 255.0
                    img_tensor = self.normalize(img_tensor).to(self.params.device)

                    # ã€å…³é”®ã€‘ä¼ å…¥ current_mask
                    best_dy, best_dx = sadba_mgr.find_best_position_for_sample(img_tensor, target_centroid,
                                                                               current_mask)
                    self.params.sadba_recorded_positions.add((best_dy, best_dx))
                # --- å†™å…¥æ•°æ®é€»è¾‘ ---
                if isinstance(data_item, torch.Tensor):
                    modified_data = data_item.clone()
                elif isinstance(data_item, np.ndarray):
                    modified_data = data_item.copy()
                else:
                    continue

                for k, (r, c) in enumerate(base_positions):
                    # ã€å…³é”®ã€‘å†™å…¥æ—¶ï¼Œåªå†™ mask é‡Œå¯¹åº”ä¸º 1 çš„å—
                    if current_mask[k] == 0:
                        continue

                    rr, cc = r + best_dy, c + best_dx
                    if rr < modified_data.shape[0] and (cc + 4) <= modified_data.shape[1]:
                        try:
                            if modified_data.ndim == 3:
                                modified_data[rr, cc:cc + 4, :] = 255
                            else:
                                modified_data[rr, cc:cc + 4] = 255
                        except Exception:
                            pass

                real_dataset.data[global_idx] = modified_data

            # ä¿®æ”¹æ ‡ç­¾
            try:
                if isinstance(real_dataset.targets, torch.Tensor):
                    real_dataset.targets[global_idx] = self.params.aim_target
                elif isinstance(real_dataset.targets, list):
                    real_dataset.targets[global_idx] = int(self.params.aim_target)
                else:
                    real_dataset.targets[global_idx] = self.params.aim_target
            except:
                pass

            count += 1

        visualize_backdoor_samples(self.backdoor_dataset, n_samples=16, nrow=4)
        print(f"Client {self.id} [SADBA]: Applied dynamic triggers to {count} images.")
        self.m_train_loader = DataLoader(self.backdoor_dataset, batch_size=self.params.local_bs, shuffle=True)

    def train_model(self, model, dataloader, loss_func,teacher_model=None,mask=None,pattern=None,delta_z=None,predicted_model=None):
        """
        Standard training loop for a given model and dataloader.
        """
        model.train()
        # ğŸ‘‰ æ”¶é›†ç‰¹å¾/æ ‡ç­¾/åé—¨æ ‡è®°ç”¨äºå¯è§†åŒ–
        all_features = []
        all_labels = []
        all_is_backdoor = []

        optimizer = torch.optim.SGD(model.parameters(), lr=self.params.lr, momentum=self.params.momentum)
        last_loss = None
        for _ in range(self.params.local_ep):
            for images, labels, global_indices in dataloader:
                optimizer.zero_grad()
                inputs = images.to(device=self.params.device, non_blocking=True)
                labels = labels.to(device=self.params.device, non_blocking=True)

                # åˆ¤æ–­å“ªäº›æ˜¯åé—¨æ ·æœ¬
                # is_backdoor = torch.tensor(
                #     [idx in self.backdoor_indices for idx in global_indices],
                #     dtype=torch.bool,
                #     device=self.params.device
                # )

                if self.params.poison_type==2:
                    poisoning_index = self.Implant_trigger(inputs, labels)
                # _,outputs = model(inputs)
                # å‰å‘æå–ç‰¹å¾
                features, outputs = model(inputs)
                # if delta_z is not None:
                #     new_features = features + delta_z.unsqueeze(0).expand_as(features)
                #     _, outputs = model(features=new_features)
                # åˆ†ç±»æŸå¤±
                loss_cls = loss_func(outputs, labels)

                if self.params.attack_type=='DarkFed' and self.epoch>=self.params.attack_epoch:
                    # DarkFedæ§åˆ¶
                    eu_loss = utils.Euclidean_loss(model, self.global_model, self.params)
                    cos_loss = utils.Cos_loss(local_model=model, predicted_model=predicted_model, global_model=self.global_model, params=self.params)
                    loss = loss_cls + 2 * eu_loss + 2 * cos_loss

                else:
                    loss = loss_cls

                loss.backward()
                optimizer.step()
                last_loss = loss.item()

        return model, last_loss

    def snnl_between_backdoor_and_normal(self, features, labels, backdoor_mask, temperature=0.1):
        """
        è®¡ç®—åé—¨æ ·æœ¬ä¸æ­£å¸¸æ ·æœ¬ä¹‹é—´çš„ Soft Nearest Neighbor Lossï¼ˆSNNLï¼‰ã€‚

        å‚æ•°ï¼š
        - features: [B, D] ç‰¹å¾å‘é‡ï¼ˆå»ºè®®å·²å½’ä¸€åŒ–ï¼‰
        - labels:   [B] æ ‡ç­¾
        - backdoor_mask: [B] å¸ƒå°”å¼ é‡ï¼ŒTrue è¡¨ç¤ºåé—¨æ ·æœ¬
        - temperature: æ§åˆ¶ç›¸ä¼¼åº¦å¹³æ»‘åº¦
        """
        if backdoor_mask.sum() == 0 or (~backdoor_mask).sum() == 0:
            return torch.tensor(0.0, device=features.device)

        backdoor_feat = features[backdoor_mask]
        normal_feat = features[~backdoor_mask]
        backdoor_labels = labels[backdoor_mask]
        normal_labels = labels[~backdoor_mask]

        all_features = torch.cat([backdoor_feat, normal_feat], dim=0)
        all_labels = torch.cat([backdoor_labels, normal_labels], dim=0)

        all_features = F.normalize(all_features, p=2, dim=1)

        sim_matrix = torch.matmul(all_features, all_features.T)  # [N, N]
        exp_sim = torch.exp(sim_matrix / temperature)

        # âœ… æ›¿ä»£ fill_diagonal_ï¼Œä¸ç ´å autograd è®¡ç®—å›¾
        mask = ~torch.eye(exp_sim.size(0), device=exp_sim.device).bool()
        exp_sim = exp_sim * mask

        label_matrix = (all_labels.unsqueeze(1) == all_labels.unsqueeze(0)).float()

        numerator = (exp_sim * label_matrix).sum(dim=1)
        denominator = exp_sim.sum(dim=1) + 1e-8

        snnl_loss = -torch.log(numerator / denominator + 1e-8)
        return snnl_loss.mean()

    def snnl_align_with_target_class(self, features, labels, backdoor_mask, target_class: int):
        """
        è®©åé—¨æ ·æœ¬ç‰¹å¾å¯¹é½ç›®æ ‡ç±»åˆ«ç‰¹å¾ä¸­å¿ƒï¼ˆç‰¹å¾ç©ºé—´é è¿‘ç›®æ ‡ç±»ï¼‰ã€‚

        å‚æ•°:
        - features: [B, D]ï¼Œbatch ä¸­æ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾
        - labels: [B]ï¼Œå¯¹åº”æ ‡ç­¾
        - backdoor_mask: [B]ï¼Œå¸ƒå°”å¼ é‡ï¼Œæ ‡è®°å“ªäº›æ˜¯åé—¨æ ·æœ¬
        - target_class: intï¼Œç›®æ ‡ç±»åˆ«æ ‡ç­¾ï¼ˆé€šå¸¸ä¸º aim_targetï¼‰

        è¿”å›:
        - å¯¹é½æŸå¤±ï¼šé¼“åŠ±åé—¨æ ·æœ¬ç‰¹å¾æ¥è¿‘ç›®æ ‡ç±»ä¸­å¿ƒ
        """
        if backdoor_mask.sum() == 0:
            return torch.tensor(0.0, device=features.device)

        # è·å–åé—¨æ ·æœ¬ç‰¹å¾
        backdoor_features = features[backdoor_mask]  # [N_bd, D]

        # ä»…æå–â€œéåé—¨ä¸”æ ‡ç­¾ä¸ºç›®æ ‡ç±»â€çš„æ ·æœ¬ç‰¹å¾
        target_mask = (labels == target_class) & (~backdoor_mask)
        if target_mask.sum() == 0:
            return torch.tensor(0.0, device=features.device)
        target_features = features[target_mask]

        # æ±‚ç›®æ ‡ç±»ç‰¹å¾ä¸­å¿ƒ
        target_center = target_features.mean(dim=0, keepdim=True)  # [1, D]

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦æˆ–æ¬§æ°è·ç¦»
        # ï¼ˆä¸‹é¢ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æ–¹å¼å®ç°ï¼‰
        backdoor_features = F.normalize(backdoor_features, dim=1)
        target_center = F.normalize(target_center, dim=1)

        cos_sim = F.cosine_similarity(backdoor_features, target_center, dim=1)  # [N_bd]
        loss = 1 - cos_sim.mean()  # è¶Šæ¥è¿‘ç›®æ ‡ç±»ä¸­å¿ƒè¶Šå¥½

        return loss

    def extract_watermark(self, model, test_loader):
        """è°ƒç”¨æ°´å°ç³»ç»Ÿçš„æå–æ–¹æ³•"""
        return self.watermarker.extract_watermark(model, test_loader)

    def local_train(self, loss_func, epoch,teacher_model=None,win=6,mask=None,pattern=None,delta_z=None,predicted_model=None):
        """
        Local training for malicious client.
        Depending on the training epoch, chooses backdoor or benign training.
        Alsoæ›´æ–°å†å²æ¨¡å‹å‚æ•°è®°å½•ï¼Œç”¨äºåç»­çš„æ°´å°æ£€æµ‹å’Œè°ƒæ•´ã€‚
        """
        self.epoch = epoch
        if self.params.poison_type == 1 and self.params.attack_type == 'sadba':
            if epoch >= self.params.attack_epoch:
                # ä¼ å…¥å½“å‰çš„ global_model (self.global_model)
                self.apply_sadba_dynamic_trigger(self.global_model)
                dataloader = self.m_train_loader
            else:
                dataloader = self.train_loader

        elif self.params.poison_type==1:
            if epoch >= self.params.attack_epoch:
                dataloader = self.m_train_loader
            else:
                dataloader = self.train_loader
        else:
            dataloader=self.train_loader

        local_model = copy.deepcopy(self.global_model)
        local_model, last_loss = self.train_model(local_model, dataloader, loss_func, teacher_model=teacher_model,mask=mask,pattern=pattern,delta_z=delta_z,predicted_model=predicted_model)
        return local_model, last_loss

    def get_watermark_positions(self, pred_class, num_classes, client_id, watermark_length):
        """
        ç¡®å®šæ€§ä½ç½®é€‰æ‹©ç®—æ³•
        """
        # 1. æ’é™¤é¢„æµ‹ç±»åˆ«
        all_positions = list(range(num_classes))
        all_positions.remove(pred_class)

        # 2. ä½¿ç”¨å®¢æˆ·ç«¯IDç”Ÿæˆéšæœºç§å­
        seed = client_id % 1000000  # ç¡®ä¿åœ¨åˆç†èŒƒå›´å†…
        rng = np.random.RandomState(seed)

        # 3. å›ºå®šé¡ºåºæ’åˆ—
        rng.shuffle(all_positions)

        # 4. é€‰æ‹©å‰watermark_lengthä¸ªä½ç½®
        return sorted(all_positions[:watermark_length])  # æ’åºç¡®ä¿é¡ºåºä¸€è‡´
    # æ³¨å…¥åé—¨
    def Implant_trigger(self, data, label):
        n = int(len(data) * self.poisoning_proportion)
        index = list(range(0, n + 1))
        poisoning_index = []
        for i in index:
            if label[i] == self.params.aim_target:
                continue
            else:
                data[i] = (1 - self.mask) * data[i] + self.mask * self.pattern
                label[i] = self.params.aim_target
                poisoning_index.append(i)
        return poisoning_index

    def Make_pattern(self):
        full_image = torch.zeros(self.input_shape)
        full_image.fill_(self.mask_value)
        x_bot = self.x_top + self.pattern_tensor.shape[0]
        y_bot = self.y_top + self.pattern_tensor.shape[1]

        if x_bot >= self.input_shape[1] or y_bot >= self.input_shape[2]:
            raise ValueError(...)

        full_image[:, self.x_top:x_bot, self.y_top:y_bot] = self.pattern_tensor
        self.mask = 1 * (full_image != self.mask_value).to(self.params.device)
        self.pattern = self.normalize(full_image).to(self.params.device)

    # å¯è§†åŒ– logits è¾“å‡ºä¸ºæ¡å½¢å›¾
    @staticmethod
    def visualize_logits(outputs, labels, epoch=0, batch_idx=0, save_dir="logits_vis", max_samples=5, prefix="train"):
        """
        å¯è§†åŒ– logits è¾“å‡ºä¸ºæ¡å½¢å›¾ã€‚

        å‚æ•°:
        - outputs: æ¨¡å‹çš„åŸå§‹è¾“å‡º logitsï¼Œå½¢çŠ¶ [B, C]
        - labels: å¯¹åº”æ ‡ç­¾
        - epoch: å½“å‰ epochï¼ˆç”¨äºå‘½åï¼‰
        - batch_idx: å½“å‰ batch ç´¢å¼•
        - save_dir: ä¿å­˜ç›®å½•
        - max_samples: æœ€å¤šå¯è§†åŒ–çš„æ ·æœ¬æ•°é‡
        - prefix: æ–‡ä»¶åå‰ç¼€ï¼ˆåŒºåˆ† train/test ç­‰ï¼‰
        """
        os.makedirs(save_dir, exist_ok=True)

        logits = outputs.detach().cpu()
        labels = labels.detach().cpu()

        N = min(max_samples, logits.shape[0])
        for i in range(N):
            plt.figure(figsize=(6, 3))
            plt.bar(range(logits.shape[1]), logits[i].numpy(), color='skyblue')
            plt.title(f"[{prefix}] Epoch {epoch} Batch {batch_idx} | Label: {labels[i].item()}")
            plt.xlabel("Class Index")
            plt.ylabel("Logit Value")
            plt.tight_layout()
            save_path = os.path.join(save_dir, f"{prefix}_logits_e{epoch}_b{batch_idx}_s{i}.png")
            plt.savefig(save_path)
            plt.close()


def visualize_tsne(features, labels, is_backdoor, title='t-SNE Feature Map', save=False, save_path=None):
    """
    t-SNE å¯è§†åŒ–ï¼šæ­£å¸¸æ ·æœ¬æŒ‰æ ‡ç­¾ç€è‰²ï¼Œåé—¨æ ·æœ¬ä¸ºé»‘è‰²ã€‚
    """
    from sklearn.manifold import TSNE
    import matplotlib.pyplot as plt
    import numpy as np

    perplexity = min(30, len(features) - 1)  # ç¡®ä¿åˆæ³•
    if perplexity < 5:
        print(f"[Skip t-SNE] Too few samples: {len(features)}")
        return

    tsne = TSNE(n_components=2, perplexity=perplexity, learning_rate=200, n_iter=1000, random_state=42)
    reduced = tsne.fit_transform(features)

    plt.figure(figsize=(10, 8))

    normal_labels = labels[~is_backdoor]
    unique_normal_labels = np.unique(normal_labels)
    colormap = plt.cm.get_cmap('tab20', len(unique_normal_labels))

    for i, label in enumerate(unique_normal_labels):
        idxs = (labels == label) & (~is_backdoor)
        plt.scatter(reduced[idxs, 0], reduced[idxs, 1],
                    label=f'Class {label}',
                    color=colormap(i),
                    s=12, alpha=0.7)

    # åé—¨æ ·æœ¬ç»Ÿä¸€ä¸ºé»‘è‰²
    idxs_bd = is_backdoor
    plt.scatter(reduced[idxs_bd, 0], reduced[idxs_bd, 1],
                label='Backdoor',
                color='black',
                s=15, alpha=0.8, marker='x')

    plt.legend()
    plt.title(title)
    plt.tight_layout()

    if save and save_path:
        plt.savefig(save_path, dpi=300)
    plt.show()

def visualize_backdoor_samples(dataset, n_samples=1, nrow=4):
    """
    å¯è§†åŒ–åé—¨æ•°æ®é›†ä¸­çš„æ ·æœ¬

    Args:
        dataset (Dataset): åé—¨æ•°æ®é›†
        n_samples (int): è¦å±•ç¤ºå¤šå°‘å¼ å›¾ç‰‡
        nrow (int): æ¯è¡Œæ˜¾ç¤ºå¤šå°‘å¼ ï¼ˆå½“ n_samples > 1 æ—¶ç”Ÿæ•ˆï¼‰
    """
    global _has_visualized
    if _has_visualized:
        return  # å·²ç»æ˜¾ç¤ºè¿‡ï¼Œç›´æ¥è·³è¿‡
    _has_visualized = True
    if len(dataset) == 0:
        print("Dataset is empty, cannot visualize.")
        return

    # é™åˆ¶å±•ç¤ºæ•°é‡
    n_samples = min(n_samples, len(dataset))

    images, labels = [], []
    for i in range(n_samples):
        img, label, global_idx = dataset[i]
        labels.append(f"L{label}|Idx{global_idx}")
        images.append(img)

    if n_samples == 1:
        # å•å¼ å›¾
        img = images[0]
        if torch.is_tensor(img):
            if img.shape[0] == 1:  # MNIST
                img_show = TF.to_pil_image(img.squeeze(0))
                cmap = "gray"
            else:  # CIFAR10
                img_show = TF.to_pil_image(img)
                cmap = None
        else:
            img_show = img
            cmap = None

        plt.imshow(img_show, cmap=cmap)
        plt.title(labels[0])
        plt.axis("off")
        plt.show()

    else:
        # å¤šå¼ æ‹¼æˆ grid
        grid = make_grid(images, nrow=nrow, normalize=True, scale_each=True)
        plt.figure(figsize=(nrow * 2, (n_samples // nrow + 1) * 2))
        plt.imshow(TF.to_pil_image(grid))
        plt.title(" | ".join(labels))
        plt.axis("off")
        plt.show()

